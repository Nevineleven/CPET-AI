{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ns/cpet-ai/CPET-AI/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel, ViTConfig\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean: tensor([0.6479, 0.7233, 0.7550]), Global std: tensor([0.3835, 0.3325, 0.2662])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.startswith('heatmap_') and f.endswith('.png')]\n",
    "        self.image_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # Sort by index number\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Extract index from filename (e.g., 2079 from heatmap_2079.png)\n",
    "        index = int(self.image_files[idx].split('_')[1].split('.')[0])\n",
    "        \n",
    "        return image, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "transform_raw = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize to ViT input size\n",
    "        transforms.ToTensor(),\n",
    "        # No normalization here - we'll compute and apply global stats later\n",
    "    ]\n",
    ")\n",
    "\n",
    "# We'll need to compute global mean and std across the dataset\n",
    "def compute_global_stats(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=32, num_workers=0)\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images = 0\n",
    "    \n",
    "    # Compute mean\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "    \n",
    "    mean = mean / total_images\n",
    "    \n",
    "    # Compute std\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        std += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
    "    \n",
    "    std = torch.sqrt(std / (total_images * images.size(2)))\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = ImageDataset(image_dir='/Users/ns/Downloads/heatmaps', transform=transform_raw)\n",
    "\n",
    "# Compute global mean and std\n",
    "mean, std = compute_global_stats(dataset)\n",
    "print(f\"Global mean: {mean}, Global std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize to ViT input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.6479, 0.7233, 0.7550],  # These are precomputed global stats, recalculate if the datset changes\n",
    "            std=[0.3835, 0.3325, 0.2662]  # # These are precomputed global stats, recalculate if the datset changes\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "config = ViTConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(features, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     22\u001b[0m features \u001b[38;5;241m=\u001b[39m [features[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(features))]\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Create dataset with normalization transform\n",
    "dataset = ImageDataset(image_dir='/Users/ns/Downloads/heatmaps', transform=transform)\n",
    "\n",
    "# Create dataloader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Extract features\n",
    "features = []\n",
    "vit_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in dataloader:\n",
    "        # Get model outputs\n",
    "        outputs = vit_model(images)\n",
    "\n",
    "        cls_features = outputs.last_hidden_state[:, 0, :]\n",
    "        features.append(cls_features)\n",
    "\n",
    "# Concatenate all features\n",
    "features = torch.cat(features, dim=0).cpu().numpy()\n",
    "features = [features[i] for i in range(len(features))]\n",
    "print(f\"Extracted features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features with shape (2089, 768) to vit_features.npy\n"
     ]
    }
   ],
   "source": [
    "# Save features to disk using numpy\n",
    "import numpy as np\n",
    "features = np.array(features)  # Convert list to numpy array\n",
    "np.save('vit_features.npy', features)\n",
    "print(f\"Saved features with shape {features.shape} to vit_features.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features with shape (2089, 768) from vit_features.npy\n",
      "Combined features shape after adding demographics: (2089, 768)\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "use_only_demographics = False  # Set to True to use only demographic features\n",
    "\n",
    "# Load saved features\n",
    "features = np.load('vit_features.npy')\n",
    "print(f\"Loaded features with shape {features.shape} from vit_features.npy\")\n",
    "df_interpolated, filtered_time_series_columns = preprocess_data('/Users/ns/Downloads/combined_outcome_df.parquet')\n",
    "y = df_interpolated[\"composite_outcome\"]\n",
    "\n",
    "# Add demographic features to the feature arrays\n",
    "demographic_columns = ['Gender', 'Age', 'Height', 'Weight', 'TestDuration', \n",
    "                      'ExerciseDuration', 'BarometricPress', 'AmbientTemp', 'AmbientRH']\n",
    "\n",
    "# Convert Gender to numeric (0 for Female, 1 for Male)\n",
    "df_interpolated['Gender'] = df_interpolated['Gender'].map({'Female': 0, 'Male': 1})\n",
    "\n",
    "# Get demographic features from df_interpolated\n",
    "demographic_features = df_interpolated[demographic_columns].values\n",
    "\n",
    "\n",
    "if use_only_demographics:\n",
    "    features = demographic_features\n",
    "    print(f\"Using only demographic features with shape: {features.shape}\")\n",
    "else:\n",
    "    # Combine ViT features with demographic features\n",
    "    #features = np.hstack([features, demographic_features])\n",
    "    print(f\"Combined features shape after adding demographics: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results over 5 runs:\n",
      "Mean ROC AUC: 0.624 ± 0.022\n",
      "Min ROC AUC: 0.595\n",
      "Max ROC AUC: 0.652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize list to store AUC scores\n",
    "auc_scores = []\n",
    "\n",
    "# Run 100 iterations with different random splits\n",
    "for i in range(5):\n",
    "    # Split data into train/test sets, stratified by outcome\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, y, \n",
    "        test_size=0.3,\n",
    "        random_state=i,  # Different random state each iteration\n",
    "        stratify=y,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train logistic regression with L1 regularization\n",
    "    model = LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='liblinear',\n",
    "        random_state=i,\n",
    "        C=1\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get prediction probabilities\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "    # Print progress every 10 iterations\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Completed {i + 1} iterations...\")\n",
    "\n",
    "# Calculate and print statistics\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "print(f\"\\nResults over {len(auc_scores)} runs:\")\n",
    "print(f\"Mean ROC AUC: {mean_auc:.3f} ± {std_auc:.3f}\")\n",
    "print(f\"Min ROC AUC: {min(auc_scores):.3f}\")\n",
    "print(f\"Max ROC AUC: {max(auc_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 iterations...\n",
      "\n",
      "Results over 10 runs:\n",
      "Mean ROC AUC: 0.678 ± 0.025\n",
      "Min ROC AUC: 0.638\n",
      "Max ROC AUC: 0.716\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize lists to store results\n",
    "auc_scores = []\n",
    "\n",
    "# Run multiple iterations\n",
    "for i in range(10):\n",
    "    # Split data into train/test sets, stratified by outcome \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, y,\n",
    "        test_size=0.3, \n",
    "        random_state=i,  # Different random state each iteration\n",
    "        stratify=y,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Train XGBoost classifier\n",
    "    model = XGBClassifier(\n",
    "        max_depth=2,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.5,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get prediction probabilities\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "    # Print progress every 10 iterations\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Completed {i + 1} iterations...\")\n",
    "\n",
    "# Calculate and print statistics\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "print(f\"\\nResults over {len(auc_scores)} runs:\")\n",
    "print(f\"Mean ROC AUC: {mean_auc:.3f} ± {std_auc:.3f}\")\n",
    "print(f\"Min ROC AUC: {min(auc_scores):.3f}\")\n",
    "print(f\"Max ROC AUC: {max(auc_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5033\n",
      "Epoch 2/10, Loss: 0.4085\n",
      "Epoch 3/10, Loss: 0.4013\n",
      "Epoch 4/10, Loss: 0.3984\n",
      "Epoch 5/10, Loss: 0.3873\n",
      "Epoch 6/10, Loss: 0.3840\n",
      "Epoch 7/10, Loss: 0.3815\n",
      "Epoch 8/10, Loss: 0.3789\n",
      "Epoch 9/10, Loss: 0.3780\n",
      "Epoch 10/10, Loss: 0.3757\n",
      "Training features shape: (1671, 768)\n",
      "Test features shape: (418, 768)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "from preprocess import preprocess_data\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "config = ViTConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Freeze all weights except pooler\n",
    "for name, param in vit_model.named_parameters():\n",
    "    if 'pooler' not in name:  # Only pooler weights remain unfrozen\n",
    "        param.requires_grad = False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize to ViT input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.6479, 0.7233, 0.7550],  # These are precomputed global stats, recalculate if the datset changes\n",
    "            std=[0.3835, 0.3325, 0.2662]  # # These are precomputed global stats, recalculate if the datset changes\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "class ImageDatasetLabels(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.startswith('heatmap_') and f.endswith('.png')]\n",
    "        self.image_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # Sort by index number\n",
    "        df_interpolated, filtered_time_series_columns = preprocess_data('/Users/ns/Downloads/combined_outcome_df.parquet')\n",
    "        self.labels = df_interpolated[\"composite_outcome\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Extract index from filename (e.g., 2079 from heatmap_2079.png)\n",
    "        index = int(self.image_files[idx].split('_')[1].split('.')[0])\n",
    "        \n",
    "        return image, torch.tensor(self.labels.iloc[idx])\n",
    "\n",
    "# Create dataset with normalization transform\n",
    "dataset = ImageDatasetLabels(image_dir='/Users/ns/Downloads/heatmaps', transform=transform)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use the built-in pooler\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, vit_model.parameters()), lr=1e-5)  # Only optimize unfrozen params\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "vit_model.train()\n",
    "\n",
    "# Add classification head\n",
    "classifier = nn.Linear(768, 1)  # Project from pooler_output dim to binary classification\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get ViT outputs - pooled_output is already available\n",
    "        outputs = vit_model(images)\n",
    "        pooled_output = outputs.pooler_output  # This is the built-in pooled representation\n",
    "        \n",
    "        # Add a simple projection to get logits\n",
    "        logits = classifier(pooled_output).squeeze()\n",
    "        loss = criterion(logits, labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Extract final features\n",
    "train_features = []\n",
    "test_features = []\n",
    "vit_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Extract training features\n",
    "    for images, _ in train_loader:\n",
    "        outputs = vit_model(images)\n",
    "        pooled_features = outputs.pooler_output\n",
    "        train_features.append(pooled_features)\n",
    "    \n",
    "    # Extract test features\n",
    "    for images, _ in test_loader:\n",
    "        outputs = vit_model(images)\n",
    "        pooled_features = outputs.pooler_output\n",
    "        test_features.append(pooled_features)\n",
    "\n",
    "# Concatenate features\n",
    "train_features = torch.cat(train_features, dim=0).cpu().numpy()\n",
    "test_features = torch.cat(test_features, dim=0).cpu().numpy()\n",
    "print(f\"Training features shape: {train_features.shape}\")\n",
    "print(f\"Test features shape: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to numpy files\n",
    "import numpy as np\n",
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.6966\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC on test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Extract test labels from test dataset\n",
    "test_labels = []\n",
    "for _, labels in test_loader:\n",
    "    test_labels.append(labels)\n",
    "test_labels = torch.cat(test_labels, dim=0).cpu().numpy()\n",
    "\n",
    "# Get predictions on test set\n",
    "test_logits = classifier(torch.from_numpy(test_features)).squeeze().detach().numpy()\n",
    "test_preds = 1 / (1 + np.exp(-test_logits))  # Apply sigmoid to get probabilities\n",
    "\n",
    "# Calculate ROC AUC\n",
    "test_roc_auc = roc_auc_score(test_labels, test_preds)\n",
    "print(f\"Test ROC AUC: {test_roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
